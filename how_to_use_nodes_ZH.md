# **节点使用说明**

## API LLM节点
1. 大模型节点可以自定义模型名称、温度、API_KEY、base_url，目前暂时只支持openai类型的API接口调用。
2. 可以直接在节点上输入系统提示词、用户提示词，也可以右键将这两个小组件转化成节点的输入，接受字符串类型的输入。
3. 大模型节点还可以从tools接口接受工具节点的输出，可以从file_content接口接受字符串形式的输入，这些输入会被当作模型的知识库，以词向量相似度来搜索相关的内容输入到模型中。
4. 大模型节点的is_memory可以决定大模型是否拥有记忆，可以将is_memory改为disable，再运行，这时模型会清楚之前的对话记录，再切换回enable，之后的运行中模型就会保留与你的对话记录。
5. 可以通过assistant_response来查看本轮对话中模型的回复，也可以通过history来查看多轮对话的历史记录。
6. 即使外部参数不变，大模型节点总是会运行，因为大模型对同一个问题也总是有着不同的回答。
7. is_tools_in_sys_prompt决定了tools的信息是否会输入到系统提示词中。
8. is_locked可以锁住上轮对话的结果，让大模型直接返回上轮对话中的回答。
9. main_brain决定了大模型是不是与用户对接的模型，禁用后，LLM节点可以作为另一个LLM节点的一个工具。
10. imgbb_api_key可以输入imgbb的pi_key，LLM将适配GPT4的视觉功能。

## 本地LLM节点
1. 目前支持GLM/Llama/Qwen，不过只有GLM的工具调用是完美适配的，其他两个需要大参数版本才能正常工具调用
2. is_reload决定了在节点运行结束后是否会卸载本地模型。默认为禁用，防止重复加载大模型，增加运行时间。当显存不能支持同时运行LLM和SD时，可以启用。
3. model_path和tokenizer_path填入模型的项目文件夹即可，适配所以可以被transformer兼容的型号。
4. 其余参数与APILLM节点一致

## start_workflow和end_workflow节点
1. 你可以用这个两个节点来定义工作流的起点和终点，将你的工作流放到本项目文件夹下的workflow子文件夹。
2. 在本项目文件夹下点击setup_streamlit_app.bat，在streamlit的界面中，点击设置，替换为你的工作流。
3. 这样，你就快速构建了一个以streamlit为前端的AI应用。

## workflow_transfer节点
1. 你需要在被嵌入的工作流的开始和结尾都添加开始工作流和结束工作流节点，将这个工作流以api形式保存到comfyui_LLM_party项目的workflow_api文件夹中
2. 另开一个工作流，在这个工作流中使用工作流中转器节点，选择你要嵌入的工作流，就完成了。
3. 第一次使用工作流中转器节点时，会开启另一个8189端口，请不要关闭这个新的控制台。

## start_dialog节点和end_dialog节点
1. 这两个节点都有dialog_id，将dialog_id连接起来，让它们成一个对话存档点。当你需要将两个大模型进行循环连接时，虽然在comfyui中是不能实现的，但是可以将后一个模型的输出保存到本地，再下一次运行时，传递给前一个模型，可以使用comfyui API在其他前端中调用comfyui，只要循环调用，就可以看到两个模型的无限自我对话了。
2. start_dialog节点上有start_dialog的接口，可以作为一个对话开始时用户给出的提示词，引导大模型在用户给出的主题中讨论。

## 工具节点共同特点
1. is_enable决定了该工具是否启用，方便用户快速变更模型上挂接的工具。

## google_tool节点
1. 可以输入你的google_api_key和cse_id来使用该节点
2. 该节点会返回谷歌搜索中的前10个网址和摘要部分，你可以要求模型翻页，来看更后面的搜索结果

## check_web_tool节点
1. 可以输入你想要搜索的网址到该节点中作为模型搜索的默认网址。
2. 由于request不是万能的，有些网址会不允许爬取，本项目也不提供恶意的爬虫代码

## time_tool节点和weather_tool节点
1. 用于查询时间和天气，time_tool节点可以更改查询的默认时区，weather_tool节点未来也会增加改变默认地区的选项
2. 未来会有更多的像这样的实用节点加入到本项目中

## 解释器节点
1. 可以让大模型生成Python代码后自动运行，并获得代码的运行结果
2. 暂时只支持Python代码

## 万能解释器节点
1. 可以让大模型执行任何事情，大模型将会在一个虚拟环境里下载所需的第三方库，然后执行生成的代码。
2. 请小心使用这个工具，因为大模型会获得控制你电脑做任何事的能力！

## load_file from comfyui_LLM_party/file节点
1. 读取文件的路径在comfyui_LLM_party/file，可以将你要读取的文件放到这个路径下，然后把文件名填入该节点即可
2. 输出是一个字符串，包含了文件中所有的文字信息

## file_conbine节点和tool_conbine节点
1. 用于将多个文件节点或者多个工具节点结合成一个，再输入到大模型中
2. 这些combine节点可以套娃使用，但是tool_conbine和file_conbine不能混用，tool节点的输出都是一个特定格式的json。
