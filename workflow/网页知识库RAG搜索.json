{
  "last_node_id": 29,
  "last_link_id": 33,
  "nodes": [
    {
      "id": 17,
      "type": "show_text_party",
      "pos": [
        1070,
        288
      ],
      "size": {
        "0": 412.81817626953125,
        "1": 278.93939208984375
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 19,
          "widget": {
            "name": "text"
          },
          "label": "text"
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": null,
          "shape": 6,
          "label": "STRING"
        }
      ],
      "properties": {
        "Node name for S&R": "show_text_party"
      },
      "widgets_values": [
        "",
        "文件中关于\"Streaming mode\"的相关内容如下：\n\n1. 如果你的下游LLM/代理系统需要立即的内容传输或需要按块处理数据来交织I/O和LLM处理时间，那么Streaming mode会很有用。\n   \n2. 当你发现标准模式提供的结果不完全时，Streaming mode也会很有用。这是因为阅读器会等待更长的时间，直到页面稳定地渲染。可以通过接受标题来切换到Streaming mode。\n\n   例如，比较下面的这两条curl命令。你会看到Streaming模式最后会给你完整的信息，而标准模式则不会。因为这份文档在加载内容时使用的是Streaming模式。\n\n3. 在Reader API中有一个流程顺序：streamContent1 ----> streamContent2 ----> streamContent3 ---> ...，每一个内容都有其相应的位置和动作。"
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 26,
      "type": "show_text_party",
      "pos": [
        1070,
        633
      ],
      "size": {
        "0": 412.81817626953125,
        "1": 278.93939208984375
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "text",
          "type": "STRING",
          "link": 30,
          "widget": {
            "name": "text"
          },
          "label": "text"
        }
      ],
      "outputs": [
        {
          "name": "STRING",
          "type": "STRING",
          "links": null,
          "shape": 6,
          "label": "STRING"
        }
      ],
      "properties": {
        "Node name for S&R": "show_text_party"
      },
      "widgets_values": [
        "",
        "[{'role': 'system', 'content': '你一个强大的人工智能助手。'}, {'role': 'user', 'content': '查一下这个文件里Streaming mode相关的内容'}, {'role': 'assistant', 'content': 'Function(arguments=\\'{\\\\n  \"question\": \"Streaming mode\"\\\\n}\\', name=\\'data_base\\')'}, {'role': 'function', 'tool_call_id': 'call_lxzSXAnjV8FqE2R6iSKf0YRo', 'name': 'data_base', 'content': '文件中的相关信息如下：\\nStreaming mode is also useful if your downstream LLM/agent system requires immediate content delivery or needs to process data in chunks to interleave I/O and LLM processing times. This allows for\\nStreaming mode is useful when you find that the standard mode provides an incomplete result. This is because the Reader will wait a bit longer until the page is _stablely_ rendered. Use the\\nuntil the page is _stablely_ rendered. Use the accept-header to toggle the streaming mode:\\nFor example, compare these two curl commands below. You can see streaming one gives you complete information at last, whereas standard mode does not. This is because the content loading on this\\nReader API:  streamContent1 ----> streamContent2 ----> streamContent3 ---> ... \\n|                    |                     |\\nv                    |                     |\\n'}, {'role': 'assistant', 'content': '文件中关于\"Streaming mode\"的相关内容如下：\\n\\n1. 如果你的下游LLM/代理系统需要立即的内容传输或需要按块处理数据来交织I/O和LLM处理时间，那么Streaming mode会很有用。\\n   \\n2. 当你发现标准模式提供的结果不完全时，Streaming mode也会很有用。这是因为阅读器会等待更长的时间，直到页面稳定地渲染。可以通过接受标题来切换到Streaming mode。\\n\\n   例如，比较下面的这两条curl命令。你会看到Streaming模式最后会给你完整的信息，而标准模式则不会。因为这份文档在加载内容时使用的是Streaming模式。\\n\\n3. 在Reader API中有一个流程顺序：streamContent1 ----> streamContent2 ----> streamContent3 ---> ...，每一个内容都有其相应的位置和动作。'}]"
      ],
      "color": "#233",
      "bgcolor": "#355"
    },
    {
      "id": 28,
      "type": "ebd_tool",
      "pos": [
        188,
        306
      ],
      "size": [
        315,
        202
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [
        {
          "name": "file_content",
          "type": "STRING",
          "link": 32,
          "widget": {
            "name": "file_content"
          }
        }
      ],
      "outputs": [
        {
          "name": "tool",
          "type": "STRING",
          "links": [
            33
          ],
          "shape": 3,
          "label": "tool",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "ebd_tool"
      },
      "widgets_values": [
        "D:\\AI\\AIyuyan\\ChatGLM3\\bge-large-zh\\",
        "enable",
        "",
        "cuda",
        200,
        50,
        "disable"
      ],
      "color": "#323",
      "bgcolor": "#535"
    },
    {
      "id": 13,
      "type": "LLM",
      "pos": [
        576,
        288
      ],
      "size": {
        "0": 409.6693420410156,
        "1": 430.2230529785156
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": null,
          "label": "images"
        },
        {
          "name": "tools",
          "type": "STRING",
          "link": 33,
          "widget": {
            "name": "tools"
          },
          "label": "tools"
        },
        {
          "name": "file_content",
          "type": "STRING",
          "link": null,
          "widget": {
            "name": "file_content"
          },
          "label": "file_content"
        }
      ],
      "outputs": [
        {
          "name": "assistant_response",
          "type": "STRING",
          "links": [
            19
          ],
          "shape": 3,
          "label": "assistant_response",
          "slot_index": 0
        },
        {
          "name": "history",
          "type": "STRING",
          "links": [
            30
          ],
          "shape": 3,
          "label": "history",
          "slot_index": 1
        },
        {
          "name": "tool",
          "type": "STRING",
          "links": null,
          "shape": 3,
          "label": "tool"
        }
      ],
      "properties": {
        "Node name for S&R": "LLM"
      },
      "widgets_values": [
        "你一个强大的人工智能助手。",
        "查一下这个文件里Streaming mode相关的内容",
        "gpt-4",
        0.7,
        "disable",
        "disable",
        "disable",
        "enable",
        2048,
        "",
        "",
        "",
        "",
        ""
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 27,
      "type": "load_url",
      "pos": [
        -194,
        308
      ],
      "size": {
        "0": 315,
        "1": 82
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "file_content",
          "type": "STRING",
          "links": [
            32
          ],
          "shape": 3,
          "label": "file_content",
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "load_url"
      },
      "widgets_values": [
        "https://github.com/jina-ai/reader",
        "enable"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      19,
      13,
      0,
      17,
      0,
      "STRING"
    ],
    [
      30,
      13,
      1,
      26,
      0,
      "STRING"
    ],
    [
      32,
      27,
      0,
      28,
      0,
      "STRING"
    ],
    [
      33,
      28,
      0,
      13,
      1,
      "STRING"
    ]
  ],
  "groups": [],
  "config": {},
  "extra": {},
  "version": 0.4
}